{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ugrasegehan/IE423/blob/main/Task9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![utexas_ds_orie_divider.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "292AXQy7sDPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IE423\n",
        "Task9\n",
        "\n",
        "## Egehan Uğraş\n",
        "\n",
        "## 22003278"
      ],
      "metadata": {
        "id": "DFbpdYEl42ZC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6pXIm2gsDPC"
      },
      "source": [
        "## <font color='#475468'> Pretrained Models:</font>\n",
        "### <font color='#475468'> Can you speed up your efforts using pretrained models?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![utexas_ds_orie_divider.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "frbUX15esDPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfomers\n",
        "\n",
        "Pretrained chains of models that perform specific tasks"
      ],
      "metadata": {
        "id": "2859Wq8-scsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize"
      ],
      "metadata": {
        "id": "aQ455KlnVIpn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJk3PId9UnAn",
        "outputId": "27cc491f-ac53-4422-f7f4-42fdf23b8b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pipelines to access pre-trained models\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Wb8kfCENVGuZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis"
      ],
      "metadata": {
        "id": "GGGTJHEnaVdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary pipeline from transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "# Model\n",
        "mdlSnt = pipeline('sentiment-analysis')\n",
        "\n",
        "# Parameters - Inserted the provided example sentences\n",
        "prmStatement = [\n",
        "    \"I just received the best news of my life, and I couldn't be happier!\",\n",
        "    \"I'm extremely disappointed with the service I received; it was a complete letdown.\",\n",
        "    \"The package arrived on time, as expected.\",\n",
        "    \"The movie had great visuals, but the plot was really confusing.\"\n",
        "]\n",
        "\n",
        "# Predict\n",
        "results = mdlSnt(prmStatement)\n",
        "\n",
        "# Display the results\n",
        "for statement, result in zip(prmStatement, results):\n",
        "    print(f\"Statement: {statement}\")\n",
        "    print(f\"Sentiment: {result['label']}, Score: {result['score']}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmU2RbtVaZzv",
        "outputId": "17b6e3df-26a0-4bb9-a6bc-fb3aacdae059"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statement: I just received the best news of my life, and I couldn't be happier!\n",
            "Sentiment: POSITIVE, Score: 0.9998483657836914\n",
            "\n",
            "Statement: I'm extremely disappointed with the service I received; it was a complete letdown.\n",
            "Sentiment: NEGATIVE, Score: 0.9998224377632141\n",
            "\n",
            "Statement: The package arrived on time, as expected.\n",
            "Sentiment: POSITIVE, Score: 0.984150230884552\n",
            "\n",
            "Statement: The movie had great visuals, but the plot was really confusing.\n",
            "Sentiment: NEGATIVE, Score: 0.9958081245422363\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results seem true."
      ],
      "metadata": {
        "id": "RrCZ5m9F4pCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can perform sentiment analysis in other languages as well using `model = 'nlptown/bert-base-multilingual-uncased-sentiment'`"
      ],
      "metadata": {
        "id": "U0KSV_R_fnwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Model setup\n",
        "mdlSnt = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "# Parameters - Sentences in different languages\n",
        "prmStatements = [\n",
        "    \"Je suis tellement heureux aujourd'hui !\",  # French: I am so happy today!\n",
        "    \"Der Film war eine totale Enttäuschung.\",  # German: The movie was a total disappointment.\n",
        "    \"Il cibo qui è assolutamente delizioso.\",  # Italian: The food here is absolutely delicious.\n",
        "    \"Estou me sentindo muito triste ultimamente.\",  # Portuguese: I have been feeling very sad lately.\n",
        "    \"Estoy muy emocionado por el fin de semana.\"  # Spanish: I am very excited for the weekend.\n",
        "]\n",
        "\n",
        "# Predict sentiment for each statement\n",
        "results = mdlSnt(prmStatements)\n",
        "\n",
        "# Display results\n",
        "for statement, result in zip(prmStatements, results):\n",
        "    print(f\"Text: {statement}\\nSentiment: {result}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrWE8D-Zhh0S",
        "outputId": "fc4c5b2b-1e43-4136-b757-e8cc4d252a14"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Je suis tellement heureux aujourd'hui !\n",
            "Sentiment: {'label': '5 stars', 'score': 0.8555185198783875}\n",
            "\n",
            "Text: Der Film war eine totale Enttäuschung.\n",
            "Sentiment: {'label': '1 star', 'score': 0.839735209941864}\n",
            "\n",
            "Text: Il cibo qui è assolutamente delizioso.\n",
            "Sentiment: {'label': '5 stars', 'score': 0.5581690073013306}\n",
            "\n",
            "Text: Estou me sentindo muito triste ultimamente.\n",
            "Sentiment: {'label': '1 star', 'score': 0.41212198138237}\n",
            "\n",
            "Text: Estoy muy emocionado por el fin de semana.\n",
            "Sentiment: {'label': '5 stars', 'score': 0.6900244355201721}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it was worked with other languages as well."
      ],
      "metadata": {
        "id": "QOiB_VIq4hXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the sentiment-analysis model\n",
        "mdlSnt = pipeline('sentiment-analysis')\n",
        "\n",
        "# List of statements with varying football teams\n",
        "prmStatement = [\n",
        "    'I am a fan of Manchester City',   # Top-tier, successful team\n",
        "    'I am a fan of Arsenal',           # Historic team with recent success\n",
        "    'I am a fan of Leeds United',      # Mid-tier team with some recent challenges\n",
        "    'I am a fan of Borussia Dortmund', # Top-tier German team with passionate fanbase\n",
        "    'I am a fan of Aston Villa',       # Historic English team with fluctuating performance\n",
        "    'I am a fan of AS Roma',           # Strong Italian team with recent ups and downs\n",
        "    'I am a fan of Brentford',         # Smaller English team that recently joined the Premier League\n",
        "    'I am a fan of Wrexham AFC',       # Lower-league team with recent publicity and growth\n",
        "]\n",
        "\n",
        "# Get sentiment analysis results\n",
        "results = mdlSnt(prmStatement)\n",
        "\n",
        "# Combine statements with their results\n",
        "combined_results = list(zip(prmStatement, results))\n",
        "\n",
        "# Sort by sentiment score:\n",
        "# - Positive sentiments: sorted by score in descending order\n",
        "# - Negative sentiments: sorted by score in ascending order\n",
        "combined_results_sorted = sorted(\n",
        "    combined_results,\n",
        "    key=lambda x: (x[1]['label'] == 'NEGATIVE', -x[1]['score']) if x[1]['label'] == 'POSITIVE' else (x[1]['label'] == 'NEGATIVE', x[1]['score'])\n",
        ")\n",
        "\n",
        "# Display sorted results with formatting\n",
        "print(\"\\nFOOTBALL TEAM PREFERENCE:\\n\")\n",
        "for index, (statement, result) in enumerate(combined_results_sorted, start=1):\n",
        "    label = result['label']\n",
        "    score = result['score']\n",
        "    print(f\"{index}. \\\"{statement}\\\"\")\n",
        "    print(f\"   Sentiment: {label}\")\n",
        "    print(f\"   Score: {score:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9LsWq7p5SOA",
        "outputId": "d9b3bdb3-ed95-4e59-ef30-593c1cc3ee26"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FOOTBALL TEAM PREFERENCE:\n",
            "\n",
            "1. \"I am a fan of Manchester City\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.9993\n",
            "\n",
            "2. \"I am a fan of Aston Villa\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.9992\n",
            "\n",
            "3. \"I am a fan of Leeds United\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.9989\n",
            "\n",
            "4. \"I am a fan of Arsenal\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.9989\n",
            "\n",
            "5. \"I am a fan of Wrexham AFC\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.9981\n",
            "\n",
            "6. \"I am a fan of AS Roma\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.9979\n",
            "\n",
            "7. \"I am a fan of Borussia Dortmund\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.9975\n",
            "\n",
            "8. \"I am a fan of Brentford\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.9974\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can observe score is decreasing as long as the success of team decreases"
      ],
      "metadata": {
        "id": "5TcLnQII5qL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the sentiment-analysis model\n",
        "mdlSnt = pipeline('sentiment-analysis')\n",
        "\n",
        "# List of statements about Turkish football teams\n",
        "prmStatement = [\n",
        "    'Galatasaray’ı destekliyorum',\n",
        "    'Fenerbahçe’yi destekliyorum',\n",
        "    'Beşiktaş’ı destekliyorum',\n",
        "    'Trabzonspor’u destekliyorum',\n",
        "    'Başakşehir’i destekliyorum',\n",
        "    'Konyaspor’u destekliyorum',\n",
        "    'Alanyaspor’u destekliyorum'\n",
        "]\n",
        "\n",
        "# Get sentiment analysis results\n",
        "results = mdlSnt(prmStatement)\n",
        "\n",
        "# Combine statements with their results\n",
        "combined_results = list(zip(prmStatement, results))\n",
        "\n",
        "# Sort by sentiment score:\n",
        "# - Positive sentiments: sorted by score in descending order\n",
        "# - Negative sentiments: sorted by score in ascending order\n",
        "combined_results_sorted = sorted(\n",
        "    combined_results,\n",
        "    key=lambda x: (x[1]['label'] == 'NEGATIVE', -x[1]['score']) if x[1]['label'] == 'POSITIVE' else (x[1]['label'] == 'NEGATIVE', x[1]['score'])\n",
        ")\n",
        "\n",
        "# Display sorted results with formatting\n",
        "print(\"\\nFOOTBALL TEAM PREFERENCE:\\n\")\n",
        "for index, (statement, result) in enumerate(combined_results_sorted, start=1):\n",
        "    label = result['label']\n",
        "    score = result['score']\n",
        "    print(f\"{index}. \\\"{statement}\\\"\")\n",
        "    print(f\"   Sentiment: {label}\")\n",
        "    print(f\"   Score: {score:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s4ysOFW6Ec3",
        "outputId": "94943549-3d46-496e-ec39-f33922646e1b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FOOTBALL TEAM PREFERENCE:\n",
            "\n",
            "1. \"Galatasaray’ı destekliyorum\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.9767\n",
            "\n",
            "2. \"Başakşehir’i destekliyorum\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.9060\n",
            "\n",
            "3. \"Beşiktaş’ı destekliyorum\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.6157\n",
            "\n",
            "4. \"Konyaspor’u destekliyorum\"\n",
            "   Sentiment: POSITIVE\n",
            "   Score: 0.5104\n",
            "\n",
            "5. \"Fenerbahçe’yi destekliyorum\"\n",
            "   Sentiment: NEGATIVE\n",
            "   Score: 0.5359\n",
            "\n",
            "6. \"Trabzonspor’u destekliyorum\"\n",
            "   Sentiment: NEGATIVE\n",
            "   Score: 0.8904\n",
            "\n",
            "7. \"Alanyaspor’u destekliyorum\"\n",
            "   Sentiment: NEGATIVE\n",
            "   Score: 0.9136\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence above results are from Turkey and I am a soccer referee, I do not want to comment about them."
      ],
      "metadata": {
        "id": "ChnonL3y6Lmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is in stars as opposed to score... this is as per the model definition.  See model details in HF for more details."
      ],
      "metadata": {
        "id": "xOUDkRRLh_zt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Answering"
      ],
      "metadata": {
        "id": "FVvRaJL9aQdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1"
      ],
      "metadata": {
        "id": "eCa9aV74zBLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjP4hZdNxlRt",
        "outputId": "57be67f7-9f07-41a0-ecdb-48e0b7147f62"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "mdlQa = pipeline(\"question-answering\")\n",
        "\n",
        "# Parameters\n",
        "f = open(\"/content/drive/MyDrive/Colab Notebooks/data/task9/bread.txt\", \"r\")\n",
        "context = f.read()\n",
        "\n",
        "question = \"Where the first football ball found ?\"\n",
        "\n",
        "# Predict\n",
        "mdlQa(question = question, context = context)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnFzwGNkbgMV",
        "outputId": "8c053e2d-e1ea-488f-8e99-8e03e9c440e9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.8500589728355408,\n",
              " 'start': 11357,\n",
              " 'end': 11364,\n",
              " 'answer': 'Uruguay'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The answer is not true, Uruguay is only written it \"The first edition of the FIFA World Cup was played in 1930 in Uruguay\", so let me add more context into question."
      ],
      "metadata": {
        "id": "qp9pPjLr28cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "mdlQa = pipeline(\"question-answering\")\n",
        "\n",
        "# Parameters\n",
        "f = open(\"/content/drive/MyDrive/Colab Notebooks/data/task9/bread.txt\", \"r\")\n",
        "context = f.read()\n",
        "\n",
        "question = \"Where the first known ball game which also involved kicking took place?\"\n",
        "\n",
        "# Predict\n",
        "mdlQa(question = question, context = context)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGCIU0533WEb",
        "outputId": "a3705cb2-e101-475d-f13f-16d6652d132a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.8401570320129395, 'start': 942, 'end': 947, 'answer': 'China'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time, true result obtained"
      ],
      "metadata": {
        "id": "R9d3Lf4H4dLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2"
      ],
      "metadata": {
        "id": "Ek8YI8U-12HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "mdlQa = pipeline(\"question-answering\")\n",
        "\n",
        "# Parameters\n",
        "f = open(\"/content/drive/MyDrive/Colab Notebooks/data/task9/bread.txt\", \"r\")\n",
        "context = f.read()\n",
        "\n",
        "question = \"What material was the first soccer ball made of?\"\n",
        "\n",
        "# Predict\n",
        "mdlQa(question = question, context = context)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "celfshC210_p",
        "outputId": "b6313e8d-c061-4ae6-d605-dc0a601be381"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.2772764563560486, 'start': 430, 'end': 434, 'answer': 'rock'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It gives the true answer again"
      ],
      "metadata": {
        "id": "JXv9UotU26oU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Pretrained Transformers"
      ],
      "metadata": {
        "id": "G3qyioH3stMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize"
      ],
      "metadata": {
        "id": "d5FoRirZkuy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "a-vYbupfkggT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab9e02d-bf57-43c3-bbc9-ce1f9d7348ce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.2\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -qU\n",
        "import colab_env"
      ],
      "metadata": {
        "id": "h_QgetcOl6sm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7806091c-fb33-47b2-edee-73a9d5fab870"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/gdrive\n",
            "Creating vars.env in your Google Drive!\n"
          ]
        }
      ]
    }
  ]
}